+++ title = "Cycle-Accurate Simulator for High-Level Synthesis: A Simple Prototype" 
[extra] latex = true 
extra.author = "Yuan Zhou" 
bio = """
[Yuan Zhou](https://github.com/zhouyuan1119) is a 5th year PhD student in ECE department Computer
System Lab. He is interested in design automation for heterogeneous compute platforms, with focus on
high-level synthesis techniques for FPGAs.  """ 
+++

In this project, I proposed to implement a cycle-accurate simulator for RTL designs generated by high-level synthesis (HLS). In brief, the proposal is to use LLVM to annotate the schedule information from the HLS tool back into the LLVM code generated by HLS. We can then compile the annotated program together with the testbench code, and dump out the per-cycle value of each variable during the execution of the compiled software program. 

I have to admit this is much more challenging than I thought at the beginning. Given the limited amount of time, the current version (available [here][link] on github) implements roughly 10% of the overall functionality I wanted for my own research. I will discuss the challenges at the end of this post, and continue to develop this tool. 

[link]: https://github.com/zhouyuan1119/cycle_accurate_simulator

Some Background
-------------------------------

### High-level Synthesis

High-level synthesis (HLS) is an emerging technique that allows users to describe their hardware designs in software programming languages such as C, C++, and Python. Because there is an inherent gap between the programming models of software programming languages and hardware description languages (HDLs), current HLS tools only support a subset of the programming constructs in software languages, and users need to annotate the software code with vendor-specific pragmas/directives to obtain high-performance hardware designs from the HLS tools. A simple example of designs written with Vivado HLS, one of the most popular commercial HLS tools, is as follows:

```
int foo(int A[10], int B[10])
{
  int res = 0;
  for (int i = 0; i < 10; i ++ )
  {
  #pragma HLS pipeline II=1
    res += (A[i] * B[i]);
  }
  
  return res;
}
```

The `#pragma` inside the loop tells the HLS tool to perform full pipelining on the loop. Other optimizations such as loop unrolling, array partitioning, and dataflow (coarse-grained pipelining) are also available. 

### Cycle-Accurate Simulation

The HLS tool processes the software code and generates designs specified in HDLs, such as Verilog and VHDL. At this stage, experienced hardware designers can run simulations with the HDL code to debug and optimize the hardware design. The simulation of HDLs is performed by event-driven simulators (RTL simulators) that can dump out the value of *every* variable in the hardware design at *every* clock cycle. While such simulators provide very detailed information about the design, the simulation speed is significantly slower than just running the software version of the design. For reasonally large designs, these simulators run at thousands of cycles per second, which is not acceptable if the user wants to simulate large workloads. 

When synthesizing the software design to HDLs, the HLS tool will provide the following information: 
- Which instruction executes at which state of the Finite State Machine (FSM). This is called the **schedule**.
- Which instruction is allocated to execute at which functional unit. This is called the **binding**. 

As a result, one alternative solution of performing cycle-accurate simulation is to annotate the schedule and binding information back into the software code, and retrieve per-cycle values of variables by executing the annotated software code. Notice that this is not completely equivalent to running RTL simulation, since the variables being observed are *software variables* rather than *hardware signals*. Still, there is some correlation between these software variables and hardware signals, so the user can get some knowledge on how the hardware is executed. More importantly, running software simulation is much faster than running RTL simulation. This is very attractive for fast design space exploration in the production pipeline, and also for research purposes. 

This idea is not new. I have found two references that implemented similar tools. The first one is [FLASH][flash_paper], but it is based on a commercial compiler and is not open-sourced. The second one is [LiPPo][lippo_link], but the implementation relies on a specific report from the HLS tool that I don't have access to. As a result I have to implement one for my own research. 

[flash_paper]: https://dl.acm.org/citation.cfm?id=3293918
[lippo_link]: https://github.com/SLAM-Lab/LIPPo

Functionality
-------------------------

The current version is very simple. It only processes **pipelined loops**. In other words, it only dumps correct result for functions that are solely composed of pipelined loops. One example is given as follows:
```
int foo(int A[10], int B[10])
{
  int res = 0;
  for (int i = 0; i < 10; i ++ )
  {
  #pragma HLS pipeline II=1
    res += (A[i] * B[i]);
  }
  
  for (int i = 0; i < 10; i ++ )
  {
  #pragma HLS pipeline II=2
    res += (A[i] - B[i]);
  }
  
  return res;
}
```
Conditions and any kind of synthesizable operations are allowed in the loops, but function calls are currently not supported. After executing the annotated code, it will dump the following content through `printf`:
```
Cycle 0: i = 0
Cycle 0: res = 0
Cycle 0: exitcond1 = 0
Cycle 0: i_1 = 1
Cycle 3: empty = 0
Cycle 3: tmp_2 = 0
Cycle 0: tmp = 0
Cycle 0: A_addr = -855338688
Cycle 1: A_load = 5
Cycle 0: B_addr = -855342784
Cycle 1: B_load = 0
Cycle 2: tmp_1 = 0
Cycle 3: res_2 = 0 
Cycle 3: empty_2 = 0
Cycle 1: i = 1     
Cycle 1: res = 0  
Cycle 1: exitcond1 = 0 
Cycle 1: i_1 = 2     
Cycle 4: empty = 0 
Cycle 4: tmp_2 = 0 
Cycle 1: tmp = 1 
Cycle 1: A_addr = -855338684 
...
Total cycles:  33
```
The names are the variable names in the LLVM code rather than the C variable names. We can see that the variable values at each cycle as well as the total latency are printed. 

How It Works
------------------------------

### Gather Information

Our first step is to parse the HLS report to retrieve the schedule information. This is done by parsing a hidden text report generated by HLS for every design. There is also a hidden XML report, but the information there is more convoluted. We might consider switching to that report since it's slightly more robust to parse a properly formatted report. We are interested in the following information:
- Pipeline information: the number of pipelines in the design, depth and II of each pipeline, and the FSM states corresponding to each pipeline;
- FSM information: FSM state transitions of the design, and the conditions that trigger the state transitions;
- Schedule: the start state, end state, and latency of each instruction in the LLVM code. 

The information is parsed by a Python script and dumped into text files that are easier to process in our LLVM pass. 

### Annotate the LLVM Code

We implement a `ModulePass` to perform the annotation, since we inevitably need to add (1) global string constants, and (2) function declaration of `prinf` to the LLVM module. However, the tasks we perform are on a per-function basis. For each function, we apply the following changes to the LLVM code:
1. We maintain a counter for each function to track the "current cycle count" at any stage of the program execution.
2. For each pipelined loop, we increment the counter by the pipeline II in every iteration of the loop:
  - We create a `phi` node in the loop header so that the correct counter value is used in every iteration;
  - We update the counter value right before the backedge, and link the updated value to the `phi` node. 
3. For each instruction in the pipelined loop, we insert a `printf` call to dump the cycle count, variable name, and value. Notice that we dump the variable values at **the cycles that they are available at outputs**. Since the FSM states that the variables are available can be retrived from the HLS reports and the FSM states are **consecutive** in pipelined loops, the correct cycle count can be simply computed as `counter + variable_available_state - pipeline_start_state`. 
4. We account for the latency of the last loop iteration when we get out from the loop by incrementing the counter: `counter = counter + loop_depth - loop_II`. This instruction is inserted at the loop exit. 
5. If there are multiple pipelined loops in the design, the counter computed at step 4 is passed on to the `phi` node we create for the next loop (step 2). For the first pipelined loop, the initial value of the counter is 0. 
6. We print the final counter value in the last basic block of the function. 

### Run the Annotated Code

The annotation is performed by using `opt` to run our LLVM pass. We then use `llc` to compile the annotated code to binary, and finally call `gcc` to link this binary with the testbench code. We have provided shortcuts for all these steps in a `Makefile` . 

Evaluation
---------------------

The current version is not powerful enough to handle realistic benchmarks yet. As a result, we verify the correctness of our annotation using simple examples in the open-source repo. 
